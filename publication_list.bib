---
---


@STRING{CVPR = {Proc. IEEE Conf. on Computer Vision and Pattern	Recognition (CVPR)}}
@STRING{ECCV = {Proc. of the European Conf. on Computer Vision (ECCV)}}
@STRING{ICCV = {Proc. of the IEEE International Conf. on Computer Vision (ICCV)}}
@STRING{THREEDV = {Proc. of the International Conf. on 3D Vision (3DV)}}
@STRING{NEURIPS = {Advances in Neural Information Processing Systems (NeurIPS)}}
@STRING{ARXIV = {arXiv}}
@STRING{Drones = {Drones}}
@STRING{CAAI = {Commuynications of Chinese Association for Artificial Intelligence (CAAI)}}


@article{yu2023immersivenerf,
  title={ImmersiveNeRF: Hybrid Radiance Fields for Unbounded Immersive Light Field Reconstruction},
  author={Yu, Xiaohang and Wang, Haoxiang and Han, Yuqi and Yang, Lei and Yu, Tao and Dai, Qionghai},
  journal={arXiv preprint arXiv:2309.01374},
  img = {assets/img/publications/immersivenerf.png},
  html = {https://arxiv.org/abs/2309.01374},
  year={2023},
  booktitle = ARXIV,
}


@article{han2023super,
  title={Super-NeRF: View-consistent Detail Generation for NeRF super-resolution},
  author={Han, Yuqi and Yu, Tao and Yu, Xiaohang and Wang, Yuwang and Dai, Qionghai},
  journal={arXiv preprint arXiv:2304.13518},
  img = {assets/img/publications/supernerf.png},
  html = {https://arxiv.org/abs/2304.13518},
  year={2023},
  booktitle = ARXIV,
}

@article{drones8010022,
AUTHOR = {Han, Yuqi and Yu, Xiaohang and Luan, Heng and Suo, Jinli},
TITLE = {Event-Assisted Object Tracking on High-Speed Drones in Harsh Illumination Environment},
JOURNAL = {Drones},
VOLUME = {8},
YEAR = {2024},
NUMBER = {1},
ARTICLE-NUMBER = {22},
img = {assets/img/publications/Drones.png},
html = {https://www.mdpi.com/2504-446X/8/1/22},
ISSN = {2504-446X},
ABSTRACT = {Drones have been used in a variety of scenarios, such as atmospheric monitoring, fire rescue, agricultural irrigation, etc., in which accurate environmental perception is of crucial importance for both decision making and control. Among drone sensors, the RGB camera is indispensable for capturing rich visual information for vehicle navigation but encounters a grand challenge in high-dynamic-range scenes, which frequently occur in real applications. Specifically, the recorded frames suffer from underexposure and overexposure simultaneously and degenerate the successive vision tasks. To solve the problem, we take object tracking as an example and leverage the superior response of event cameras over a large intensity range to propose an event-assisted object tracking algorithm that can achieve reliable tracking under large intensity variations. Specifically, we propose to pursue feature matching from dense event signals and, based on this, to (i) design a U-Net-based image enhancement algorithm to balance RGB intensity with the help of neighboring frames in the time domain and then (ii) construct a dual-input tracking model to track the moving objects from intensity-balanced RGB video and event sequences. The proposed approach is comprehensively validated in both simulation and real experiments.},
DOI = {10.3390/drones8010022},
booktitle = Drones,
}


@article{yu2023immersive,
  title={Acquisition, Representation, and Application of Immersive Light Field },
  author={Han, Yuqi and Yu, Xiaohang and Yu, Tao},
  journal={arXiv preprint arXiv:2309.01374},
  img = {assets/img/publications/lightfield.png},
  html = {https://www.caai.cn/index.php?s=/home/article/qikandetail/year/2023/month/09.html},
  year={2023},
  booktitle = CAAI,
}




